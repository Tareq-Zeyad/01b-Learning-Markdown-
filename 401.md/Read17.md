# Web Scraping


# What is Web Scraping ?

Web Scraping is a method used for extracting data from websites. The web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.




# How is this process done ?

Web scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be to find and copy names and telephone numbers, or companies and their URLs, or e-mail addresses to a list (contact scraping).



# What are the Web Scraping Techniques

* Human copy-and-paste

* Text pattern matching

* HTTP programming

* HTML parsing

* DOM parsing

* Vertical aggregation

* Semantic annotation recognizing

* Computer vision web-page analysis

Detailed Explantion for each one can be found on [this wiki](https://en.wikipedia.org/wiki/Web_scraping)


# What software do we use to scrape the web ?

By Scripting functions that can be used to extract & transform content as well as database interfaces that can store the scraped data in local databases.


# How to Web Scrape without getting blocked ?

1. Use IP Rotation

2. Use Google Cloud Platform IPs

3. Set Additional Request Headers

4. Set A Referrer

5. Web Scrape slowly

6. Pursue Different Scraping Patterns

